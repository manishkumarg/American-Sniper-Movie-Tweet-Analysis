{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American Sniper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If American Sniper doesn't make you proud to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fav if you're going to see the movie American ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     American Sniper\n",
       "0  If American Sniper doesn't make you proud to b...\n",
       "1  Retweet if you're going to see the movie Ameri...\n",
       "2  Retweet if you're going to see the movie Ameri...\n",
       "3  Retweet if you're going to see the movie Ameri...\n",
       "4  Fav if you're going to see the movie American ..."
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#fwf stands for fixed width formatted lines\n",
    "\n",
    "df =  pd.read_fwf('C:/manish/personal/Tavant/InterviewAssignment/tweets.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100037 entries, 0 to 100036\n",
      "Data columns (total 1 columns):\n",
      "American Sniper    100037 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 781.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: \n",
    "#####  Break the twitter hashtags into proper words\n",
    "Ex : #goldenglobes -> golden globes ,  #siennamiller -> sienna miller \n",
    "    \n",
    "\n",
    "##### Creating a new column HashTag for words startswith '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American Sniper</th>\n",
       "      <th>HashTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If American Sniper doesn't make you proud to b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fav if you're going to see the movie American ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I just watched American Sniper. You have to se...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Did you know #Jesseventura sued fallen seal es...</td>\n",
       "      <td>Jesseventura, AmericanSniper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>American Sniper kind of reminds me of the movi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Did yâ€™all see \"American Sniper\"? What a powe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>american sniper Ù‚ØµØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© 2015  1- h...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     American Sniper  \\\n",
       "0  If American Sniper doesn't make you proud to b...   \n",
       "1  Retweet if you're going to see the movie Ameri...   \n",
       "2  Retweet if you're going to see the movie Ameri...   \n",
       "3  Retweet if you're going to see the movie Ameri...   \n",
       "4  Fav if you're going to see the movie American ...   \n",
       "5  I just watched American Sniper. You have to se...   \n",
       "6  Did you know #Jesseventura sued fallen seal es...   \n",
       "7  American Sniper kind of reminds me of the movi...   \n",
       "8  Did yâ€™all see \"American Sniper\"? What a powe...   \n",
       "9  american sniper Ù‚ØµØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© 2015  1- h...   \n",
       "\n",
       "                       HashTags  \n",
       "0                                \n",
       "1                                \n",
       "2                                \n",
       "3                                \n",
       "4                                \n",
       "5                                \n",
       "6  Jesseventura, AmericanSniper  \n",
       "7                                \n",
       "8                                \n",
       "9                                "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Extracting '#' from df\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "## Converting to string\n",
    "df['American Sniper'] = df['American Sniper'].astype('str')\n",
    "\n",
    "df['Clean_American Sniper'] = df['American Sniper']\n",
    "df['Clean_American Sniper'] = df['Clean_American Sniper'].astype('str')\n",
    "#df['Clean_American Sniper'] = df['Clean_American Sniper'].str.lower()\n",
    "\n",
    "def hashtag_extractor(s):\n",
    "    #s = s.replace('\\n',' ')\n",
    "    split = re.compile(r'#(\\w+)')\n",
    "    x = split.findall(s) \n",
    "    x = ', '.join(x)\n",
    "\n",
    "    if len(x)>0:\n",
    "        return x\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "df['HashTags'] = ''\n",
    "df['HashTags'] = df['Clean_American Sniper'].map(lambda x: hashtag_extractor(x))\n",
    "\n",
    "\n",
    "## Drop Clean_American Sniper as not going to be used:\n",
    "df.drop(labels='Clean_American Sniper',axis=1,inplace=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: \n",
    "\n",
    "The problem can be broken down to several steps:\n",
    "\n",
    "\n",
    "\n",
    "   Populate a list with English words(words.txt is the populated file)\n",
    "    __[https://github.com/dwyl/english-words/blob/master/words.txt](http://url)__ <br>\n",
    "           Split the sentence into terms delimited by white-space. <br>\n",
    "           Treat terms starting with '#' as hashtags <br>\n",
    "           For each hashtag, find words by longest match by checking if they exist in the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American Sniper</th>\n",
       "      <th>HashTags</th>\n",
       "      <th>Split_HashTags_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If American Sniper doesn't make you proud to b...</td>\n",
       "      <td></td>\n",
       "      <td>if american sniper doesn't make you proud to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fav if you're going to see the movie American ...</td>\n",
       "      <td></td>\n",
       "      <td>fav if you're going to see the movie american ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I just watched American Sniper. You have to se...</td>\n",
       "      <td></td>\n",
       "      <td>i just watched american sniper. you have to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Did you know #Jesseventura sued fallen seal es...</td>\n",
       "      <td>Jesseventura, AmericanSniper</td>\n",
       "      <td>did you know  sued fallen seal estate american...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>American Sniper kind of reminds me of the movi...</td>\n",
       "      <td></td>\n",
       "      <td>american sniper kind of reminds me of the movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Did yâ€™all see \"American Sniper\"? What a powe...</td>\n",
       "      <td></td>\n",
       "      <td>did yâ€™all see \"american sniper\"? what a powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>american sniper Ù‚ØµØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© 2015  1- h...</td>\n",
       "      <td></td>\n",
       "      <td>american sniper ù‚øµø© ø­ù‚ùšù‚ùšø© 2015 1- ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     American Sniper  \\\n",
       "0  If American Sniper doesn't make you proud to b...   \n",
       "1  Retweet if you're going to see the movie Ameri...   \n",
       "2  Retweet if you're going to see the movie Ameri...   \n",
       "3  Retweet if you're going to see the movie Ameri...   \n",
       "4  Fav if you're going to see the movie American ...   \n",
       "5  I just watched American Sniper. You have to se...   \n",
       "6  Did you know #Jesseventura sued fallen seal es...   \n",
       "7  American Sniper kind of reminds me of the movi...   \n",
       "8  Did yâ€™all see \"American Sniper\"? What a powe...   \n",
       "9  american sniper Ù‚ØµØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© 2015  1- h...   \n",
       "\n",
       "                       HashTags  \\\n",
       "0                                 \n",
       "1                                 \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "5                                 \n",
       "6  Jesseventura, AmericanSniper   \n",
       "7                                 \n",
       "8                                 \n",
       "9                                 \n",
       "\n",
       "                                    Split_HashTags_1  \n",
       "0  if american sniper doesn't make you proud to b...  \n",
       "1  retweet if you're going to see the movie ameri...  \n",
       "2  retweet if you're going to see the movie ameri...  \n",
       "3  retweet if you're going to see the movie ameri...  \n",
       "4  fav if you're going to see the movie american ...  \n",
       "5  i just watched american sniper. you have to se...  \n",
       "6  did you know  sued fallen seal estate american...  \n",
       "7  american sniper kind of reminds me of the movi...  \n",
       "8  did yâ€™all see \"american sniper\"? what a powe...  \n",
       "9  american sniper ù‚øµø© ø­ù‚ùšù‚ùšø© 2015 1- ht...  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['American Sniper'] = df['American Sniper'].astype('str')\n",
    "\n",
    "df['Clean_American Sniper'] = df['American Sniper']\n",
    "df['Clean_American Sniper'] = df['Clean_American Sniper'].astype('str')\n",
    "df['Clean_American Sniper'] = df['Clean_American Sniper'].str.lower()\n",
    "\n",
    "def initialize_words():\n",
    "    content = None\n",
    "    with open('C:/manish/personal/Tavant/InterviewAssignment/words.txt') as f: # A file containing common english words\n",
    "        content = f.readlines()\n",
    "    return [word.rstrip('\\n') for word in content]\n",
    "\n",
    "def parse_sentence(sentence, wordlist):\n",
    "    new_sentence = \"\" # output    \n",
    "    terms = sentence.split(' ')\n",
    "    terms = [i for i in terms if i != '']\n",
    "    for term in terms:\n",
    "        if term[0] == '#': # this is a hashtag, parse it\n",
    "            new_sentence += parse_tag(term, wordlist)\n",
    "        else: # Just append the word\n",
    "            new_sentence += term\n",
    "        new_sentence += \" \"\n",
    "\n",
    "    return new_sentence \n",
    "\n",
    "def parse_tag(term, wordlist):\n",
    "    words = []\n",
    "    # Remove hashtag, split by dash\n",
    "    tags = term[1:].split('-')\n",
    "    for tag in tags:\n",
    "        word = find_word(tag, wordlist)    \n",
    "        while word != None and len(tag) > 0:\n",
    "            words.append(word)            \n",
    "            if len(tag) == len(word): # Special case for when eating rest of word\n",
    "                break\n",
    "            tag = tag[len(word):]\n",
    "            word = find_word(tag, wordlist)\n",
    "    return \" \".join(words)\n",
    "\n",
    "def find_word(token, wordlist):\n",
    "    i = len(token) + 1\n",
    "    while i > 1:\n",
    "        i -= 1\n",
    "        if token[:i] in wordlist:\n",
    "            return token[:i]\n",
    "    return None \n",
    "\n",
    "\n",
    "wordlist = initialize_words()\n",
    "#sentence = \"american sniper ù‚øµø© ø\\xadù‚ùšù‚ùšø© 2015  1- http://t.co/akg2z2pwli  2- http://t.co/fwgvmvra74  3- http://t.co/xethsjetei _ _ http://t.co/qowwnevl14\"\n",
    "#parse_sentence(sentence, wordlist)\n",
    "\n",
    "df['Split_HashTags_1'] = ''\n",
    "\n",
    "for i in range (len(df)):\n",
    "     df['Split_HashTags_1'][i] = parse_sentence(df['Clean_American Sniper'][i],wordlist)\n",
    "\n",
    "## Drop Clean_American Sniper as not going to be used:\n",
    "df.drop(labels='Clean_American Sniper',axis=1,inplace=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach 2 : Using Regex to split HashTag words only useful when CamelCasing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American Sniper</th>\n",
       "      <th>HashTags</th>\n",
       "      <th>Split_HashTags_1</th>\n",
       "      <th>Split_HashTags2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If American Sniper doesn't make you proud to b...</td>\n",
       "      <td></td>\n",
       "      <td>if american sniper doesn't make you proud to b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retweet if you're going to see the movie Ameri...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fav if you're going to see the movie American ...</td>\n",
       "      <td></td>\n",
       "      <td>fav if you're going to see the movie american ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I just watched American Sniper. You have to se...</td>\n",
       "      <td></td>\n",
       "      <td>i just watched american sniper. you have to se...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Did you know #Jesseventura sued fallen seal es...</td>\n",
       "      <td>Jesseventura, AmericanSniper</td>\n",
       "      <td>did you know  sued fallen seal estate american...</td>\n",
       "      <td>Jesseventura American Sniper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>American Sniper kind of reminds me of the movi...</td>\n",
       "      <td></td>\n",
       "      <td>american sniper kind of reminds me of the movi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Did yâ€™all see \"American Sniper\"? What a powe...</td>\n",
       "      <td></td>\n",
       "      <td>did yâ€™all see \"american sniper\"? what a powe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>american sniper Ù‚ØµØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© 2015  1- h...</td>\n",
       "      <td></td>\n",
       "      <td>american sniper ù‚øµø© ø­ù‚ùšù‚ùšø© 2015 1- ht...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     American Sniper  \\\n",
       "0  If American Sniper doesn't make you proud to b...   \n",
       "1  Retweet if you're going to see the movie Ameri...   \n",
       "2  Retweet if you're going to see the movie Ameri...   \n",
       "3  Retweet if you're going to see the movie Ameri...   \n",
       "4  Fav if you're going to see the movie American ...   \n",
       "5  I just watched American Sniper. You have to se...   \n",
       "6  Did you know #Jesseventura sued fallen seal es...   \n",
       "7  American Sniper kind of reminds me of the movi...   \n",
       "8  Did yâ€™all see \"American Sniper\"? What a powe...   \n",
       "9  american sniper Ù‚ØµØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© 2015  1- h...   \n",
       "\n",
       "                       HashTags  \\\n",
       "0                                 \n",
       "1                                 \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "5                                 \n",
       "6  Jesseventura, AmericanSniper   \n",
       "7                                 \n",
       "8                                 \n",
       "9                                 \n",
       "\n",
       "                                    Split_HashTags_1  \\\n",
       "0  if american sniper doesn't make you proud to b...   \n",
       "1  retweet if you're going to see the movie ameri...   \n",
       "2  retweet if you're going to see the movie ameri...   \n",
       "3  retweet if you're going to see the movie ameri...   \n",
       "4  fav if you're going to see the movie american ...   \n",
       "5  i just watched american sniper. you have to se...   \n",
       "6  did you know  sued fallen seal estate american...   \n",
       "7  american sniper kind of reminds me of the movi...   \n",
       "8  did yâ€™all see \"american sniper\"? what a powe...   \n",
       "9  american sniper ù‚øµø© ø­ù‚ùšù‚ùšø© 2015 1- ht...   \n",
       "\n",
       "                 Split_HashTags2  \n",
       "0                                 \n",
       "1                                 \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "5                                 \n",
       "6  Jesseventura American Sniper   \n",
       "7                                 \n",
       "8                                 \n",
       "9                                 "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Splitting HashTag words\n",
    "\n",
    "import re\n",
    "def split_hashtag(hashtagestring):\n",
    "    fo = re.compile(r'[A-Z]{2,}(?![a-z])|[A-Z][a-z]+')\n",
    "    fi = fo.findall(hashtagestring)\n",
    "#    fi = ', '.join(fi)\n",
    "    result = ''\n",
    "    for var in fi:\n",
    "        result += var + ' '\n",
    "    return (result)\n",
    "#// pass the string \"#WakeUpAmerica\" to the function\n",
    "#split_hashtage('#WakeUpAmerica')\n",
    "\n",
    "df['Split_HashTags2'] = ''\n",
    "df['Split_HashTags2'] = df['HashTags'].map(lambda x: split_hashtag(x))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2:\n",
    "\n",
    "Find out what people have said about these three personalities ( Clint Eastwood, Bradley Cooper and Chris Kyle ), in other words find out the top trending topics about these people in the current dataset.\n",
    "\n",
    "Show 5 top trends per person. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 HashTags and Mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 hashtags:\n",
      "----------------\n",
      "americansniper - 17155\n",
      "movie - 1516\n",
      "review - 1377\n",
      "chriskyle - 1181\n",
      "bradleycooper - 878\n",
      "oscarnoms - 791\n",
      "oscars2015 - 765\n",
      "honorchriskyle - 637\n",
      "tcot - 515\n",
      "clinteastwood - 440\n",
      "\n",
      "Top 10 mentions:\n",
      "----------------\n",
      "americansniper - 2996\n",
      "seanhannity - 468\n",
      "honorchriskyle - 438\n",
      "chriskylefrog - 358\n",
      "mmflint - 191\n",
      "youtube - 158\n",
      "sethrogen - 139\n",
      "theacademy - 139\n",
      "foxnews - 126\n",
      "bradleycooperus - 115\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import string\n",
    "# Hashtags & mentions\n",
    "tag_dict = {}\n",
    "mention_dict = {}\n",
    "\n",
    "for i in df.index:\n",
    "    tweet_text = df.ix[i]['American Sniper']\n",
    "    tweet = tweet_text.lower()\n",
    "    tweet_tokenized = tweet.split()\n",
    "\n",
    "    for word in tweet_tokenized:\n",
    "        # Hashtags - tokenize and build dict of tag counts\n",
    "        if (word[0:1] == '#' and len(word) > 1):\n",
    "            key = word.translate(str.maketrans('','',string.punctuation))\n",
    "            if key in tag_dict:\n",
    "                tag_dict[key] += 1\n",
    "            else:\n",
    "                tag_dict[key] = 1\n",
    "\n",
    "        # Mentions - tokenize and build dict of mention counts\n",
    "        if (word[0:1] == '@' and len(word) > 1):\n",
    "            key = word.translate(str.maketrans('','',string.punctuation))\n",
    "            if key in mention_dict:\n",
    "                mention_dict[key] += 1\n",
    "            else:\n",
    "                mention_dict[key] = 1\n",
    "\n",
    "# The 10 most popular tags and counts\n",
    "top_tags = dict(sorted(tag_dict.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
    "top_tags_sorted = sorted(top_tags.items(), key=lambda x: x[1])[::-1]\n",
    "print ('Top 10 hashtags:')\n",
    "print ('----------------')\n",
    "for tag in top_tags_sorted:\n",
    "    print (tag[0], '-', str(tag[1]))\n",
    "    \n",
    "# The 10 most popular mentions and counts\n",
    "top_mentions = dict(sorted(mention_dict.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
    "top_mentions_sorted = sorted(top_mentions.items(), key=lambda x: x[1])[::-1]\n",
    "print ('\\nTop 10 mentions:')\n",
    "print ('----------------')\n",
    "for mention in top_mentions_sorted:\n",
    "     print (mention[0], '-', str(mention[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Pre-Processing for the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [american, sniper, doesnt, make, proud, americ...\n",
       "1    [retweet, youre, go, see, movie, american, sni...\n",
       "2    [retweet, youre, go, see, movie, american, sni...\n",
       "3    [retweet, youre, go, see, movie, american, sni...\n",
       "4    [fav, youre, go, see, movie, american, sniper,...\n",
       "Name: American Sniper, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to LowerCase\n",
    "df['American Sniper'] = df['American Sniper'].astype('str').apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "# Removing Punctuations\n",
    "df['American Sniper'] = df['American Sniper'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Removal of StopWords\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['American Sniper'] = df['American Sniper'].astype('str').apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "# Reducing Word by their Root words (Lemmatization)\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "df['American Sniper'] = df['American Sniper'].astype('str').apply(lambda x: \" \".join([lmtzr.lemmatize(word,'v') for word in x.split()]))\n",
    "\n",
    "# Tweet Tokenizing\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "df['American Sniper'] = df['American Sniper'].map(lambda x: tknzr.tokenize(x))\n",
    "\n",
    "\n",
    "df['American Sniper'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 words:\n",
      "----------------\n",
      "american - 81883\n",
      "sniper - 80169\n",
      "see - 28278\n",
      "americansniper - 20451\n",
      "movie - 15182\n",
      "watch - 12378\n",
      "go - 9535\n",
      "good - 6814\n",
      "want - 6058\n",
      "wanna - 5786\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}    \n",
    "\n",
    "for i in df.index:\n",
    "    tweet_text = df.ix[i]['American Sniper']\n",
    "#    tweet = tweet_text.lower()\n",
    "    tweet_tokenized = tweet_text\n",
    "\n",
    "    for word in tweet_tokenized:\n",
    "        # Word keys - tokenize and build dict of word items other than # and @\n",
    "        if (word[0:1] != '@' or word[0:1] != '#' and len(word) > 1):\n",
    "            key = word.translate(str.maketrans('','',string.punctuation))\n",
    "            if key in word_dict:\n",
    "                word_dict[key] += 1\n",
    "            else:\n",
    "                word_dict[key] = 1\n",
    "    \n",
    "# The 10 most popular words and counts\n",
    "top_words = dict(sorted(word_dict.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
    "top_words_sorted = sorted(top_words.items(), key=lambda x: x[1])[::-1]\n",
    "print ('\\nTop 10 words:')\n",
    "print ('----------------')\n",
    "for words in top_words_sorted:\n",
    "     print (words[0], '-', str(words[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating columns for Clint, Bradley and Chris if a match found returns True else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3844\n",
      "4780\n",
      "6355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American Sniper</th>\n",
       "      <th>HashTags</th>\n",
       "      <th>Split_HashTags_1</th>\n",
       "      <th>Split_HashTags2</th>\n",
       "      <th>Clint</th>\n",
       "      <th>Bradley</th>\n",
       "      <th>Chris</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[american, sniper, doesnt, make, proud, americ...</td>\n",
       "      <td></td>\n",
       "      <td>if american sniper doesn't make you proud to b...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[retweet, youre, go, see, movie, american, sni...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[retweet, youre, go, see, movie, american, sni...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[retweet, youre, go, see, movie, american, sni...</td>\n",
       "      <td></td>\n",
       "      <td>retweet if you're going to see the movie ameri...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[fav, youre, go, see, movie, american, sniper,...</td>\n",
       "      <td></td>\n",
       "      <td>fav if you're going to see the movie american ...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     American Sniper HashTags  \\\n",
       "0  [american, sniper, doesnt, make, proud, americ...            \n",
       "1  [retweet, youre, go, see, movie, american, sni...            \n",
       "2  [retweet, youre, go, see, movie, american, sni...            \n",
       "3  [retweet, youre, go, see, movie, american, sni...            \n",
       "4  [fav, youre, go, see, movie, american, sniper,...            \n",
       "\n",
       "                                    Split_HashTags_1 Split_HashTags2  Clint  \\\n",
       "0  if american sniper doesn't make you proud to b...                  False   \n",
       "1  retweet if you're going to see the movie ameri...                  False   \n",
       "2  retweet if you're going to see the movie ameri...                  False   \n",
       "3  retweet if you're going to see the movie ameri...                  False   \n",
       "4  fav if you're going to see the movie american ...                  False   \n",
       "\n",
       "   Bradley  Chris  \n",
       "0    False  False  \n",
       "1    False  False  \n",
       "2    False  False  \n",
       "3    False  False  \n",
       "4    False  False  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 =  pd.read_fwf('C:/manish/personal/Tavant/InterviewAssignment/tweets.txt')\n",
    "import re\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df['Clint'] = df1['American Sniper'].apply(lambda tweet: word_in_text('clint', tweet))\n",
    "df['Bradley'] = df1['American Sniper'].apply(lambda tweet: word_in_text('bradley', tweet))\n",
    "df['Chris'] = df1['American Sniper'].apply(lambda tweet: word_in_text('chris', tweet))\n",
    "\n",
    "print (df['Clint'].value_counts()[True])\n",
    "print (df['Bradley'].value_counts()[True])\n",
    "print (df['Chris'].value_counts()[True])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clint Eastwood's Trending Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Clint associated words:\n",
      "----------------\n",
      "clint - 3374\n",
      "movie - 2969\n",
      "review - 2816\n",
      "americansniper - 2463\n",
      "sniperâ - 1561\n",
      "âamerican - 1534\n",
      "eastwood - 1462\n",
      "eastwoodâs - 1438\n",
      "ofâ - 1364\n",
      "interpretation - 1364\n",
      "bythebook - 1364\n",
      "american - 1330\n",
      "sniper - 1264\n",
      "httptco - 476\n",
      "clinteastwood - 445\n",
      "film - 358\n",
      "bradley - 302\n",
      "cooper - 294\n",
      "eastwoods - 276\n",
      "de - 227\n"
     ]
    }
   ],
   "source": [
    "Clint_dict = {}    \n",
    "\n",
    "for i in df.index:\n",
    "    if df['Clint'][i] == True:\n",
    "        tweet_text = df.ix[i]['American Sniper']\n",
    "        tweet_tokenized = tweet_text\n",
    "\n",
    "        for word in tweet_tokenized:\n",
    "        # Word keys - tokenize and build dict of word items other than # and @\n",
    "            if (word[0:1] != '@' or word[0:1] != '#' and len(word) > 1):\n",
    "                key = word.translate(str.maketrans('','',string.punctuation))\n",
    "                if key in Clint_dict:\n",
    "                    Clint_dict[key] += 1\n",
    "                else:\n",
    "                    Clint_dict[key] = 1\n",
    "    \n",
    "# The 10 most popular words and counts\n",
    "top_words = dict(sorted(Clint_dict.items(), key=operator.itemgetter(1), reverse=True)[:20])\n",
    "top_words_sorted = sorted(top_words.items(), key=lambda x: x[1])[::-1]\n",
    "print ('\\nTop 20 Clint associated words:')\n",
    "print ('----------------')\n",
    "for words in top_words_sorted:\n",
    "     print (words[0], '-', str(words[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bradley Cooper's Trending Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Bradley associated words:\n",
      "----------------\n",
      "bradley - 3718\n",
      "cooper - 3512\n",
      "american - 2655\n",
      "sniper - 2598\n",
      "americansniper - 2113\n",
      "bradleycooper - 894\n",
      "movie - 576\n",
      "see - 530\n",
      "kyle - 467\n",
      "chris - 423\n",
      "httptco - 405\n",
      "best - 341\n",
      "film - 314\n",
      "clint - 299\n",
      "watch - 289\n",
      "sniperâ - 287\n",
      "âamerican - 272\n",
      "eastwood - 259\n",
      "good - 241\n",
      "oscar - 232\n"
     ]
    }
   ],
   "source": [
    "Bradley_dict = {}    \n",
    "\n",
    "for i in df.index:\n",
    "    if df['Bradley'][i] == True:\n",
    "        tweet_text = df.ix[i]['American Sniper']\n",
    "        tweet_tokenized = tweet_text\n",
    "\n",
    "        for word in tweet_tokenized:\n",
    "        # Word keys - tokenize and build dict of word items other than # and @\n",
    "            if (word[0:1] != '@' or word[0:1] != '#' and len(word) > 1):\n",
    "                key = word.translate(str.maketrans('','',string.punctuation))\n",
    "                if key in Bradley_dict:\n",
    "                    Bradley_dict[key] += 1\n",
    "                else:\n",
    "                    Bradley_dict[key] = 1\n",
    "    \n",
    "# The 10 most popular words and counts\n",
    "top_words = dict(sorted(Bradley_dict.items(), key=operator.itemgetter(1), reverse=True)[:20])\n",
    "top_words_sorted = sorted(top_words.items(), key=lambda x: x[1])[::-1]\n",
    "print ('\\nTop 20 Bradley associated words:')\n",
    "print ('----------------')\n",
    "for words in top_words_sorted:\n",
    "     print (words[0], '-', str(words[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chris Kyle's Trending Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Chris associated words:\n",
      "----------------\n",
      "bradley - 3718\n",
      "cooper - 3512\n",
      "american - 2655\n",
      "sniper - 2598\n",
      "americansniper - 2113\n",
      "bradleycooper - 894\n",
      "movie - 576\n",
      "see - 530\n",
      "kyle - 467\n",
      "chris - 423\n",
      "httptco - 405\n",
      "best - 341\n",
      "film - 314\n",
      "clint - 299\n",
      "watch - 289\n",
      "sniperâ - 287\n",
      "âamerican - 272\n",
      "eastwood - 259\n",
      "good - 241\n",
      "oscar - 232\n"
     ]
    }
   ],
   "source": [
    "Chris_dict = {}    \n",
    "\n",
    "for i in df.index:\n",
    "    if df['Chris'][i] == True:\n",
    "        tweet_text = df.ix[i]['American Sniper']\n",
    "        tweet_tokenized = tweet_text\n",
    "\n",
    "        for word in tweet_tokenized:\n",
    "        # Word keys - tokenize and build dict of word items other than # and @\n",
    "            if (word[0:1] != '@' or word[0:1] != '#' and len(word) > 1):\n",
    "                key = word.translate(str.maketrans('','',string.punctuation))\n",
    "                if key in Chris_dict:\n",
    "                    Chris_dict[key] += 1\n",
    "                else:\n",
    "                    Chris_dict[key] = 1\n",
    "    \n",
    "# The 10 most popular words and counts\n",
    "top_words = dict(sorted(Bradley_dict.items(), key=operator.itemgetter(1), reverse=True)[:20])\n",
    "top_words_sorted = sorted(top_words.items(), key=lambda x: x[1])[::-1]\n",
    "print ('\\nTop 20 Chris associated words:')\n",
    "print ('----------------')\n",
    "for words in top_words_sorted:\n",
    "     print (words[0], '-', str(words[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('C:/manish/personal/Tavant/InterviewAssignment/tweets.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
